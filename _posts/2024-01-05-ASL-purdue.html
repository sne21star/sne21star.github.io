---
layout: post
title: "American Sign Language"
subtitle: "Detect ASL Language using RNN"
date: 2020-01-31 10:45:13 -0400
background: '/img/posts/project/ASL/ASL_2.gif'
category: 'Portfolio'
---

<h2 class="section-heading">Overview</h2>
<p align="justify">
    Many deaf students, whose first language is ASL, want to learn English to not only learn how to read and write, but also communicate with others who may not know ASL. 
    In order to find a solution to this problem, our team DASL (Digital American Sign Language), aims to create an On-Device, Real Time ASL Translator. 
    This idea has become a reality by use of Googleâ€™s Framework: Mediapipe. 
    In the future we hope to create our own CNN(for image classification) and RNN(video classification) to translate both static and dynamic gesture and possibly even sentences if time permits.</p> 

<div class="polaroid" align="justify">
    <img src="/sneha-mahapatra/img/posts/project/ASL/ASL_2.gif" alt="5 Terre" style="width:100%">
    <div align="justify">
    <p>ASL detection using RNN</p>
    </div>
</div>




<h2 class="section-heading">Powerpoint Presentation</h2>
This powerpoint explains at a higher level how this project was created. 

<iframe src="https://docs.google.com/presentation/d/e/2PACX-1vRdaIRJ5ZFsCKNWIDQhqaAME01Z4XvPkRXd_VT-hlKQBgol8tryG4wQX5H1rW_T52r30z3rniAhKGfr/embed?start=true&loop=false&delayms=10000" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true"></iframe>

 
<h2 class="section-heading">Hand Gesture Recognition Calculator</h2>
This is one file within the repository that shows how we embedded and called the ML model into the application 


<script src="https://gist.github.com/sne21star/b1a360c9611cd1c2f00b8188530da950.js"></script>

<h2 class="section-heading">Project</h2>

<p>
The entire code base can be found <a href="https://github.com/sne21star/mediapipe">here</a>.
</p>




